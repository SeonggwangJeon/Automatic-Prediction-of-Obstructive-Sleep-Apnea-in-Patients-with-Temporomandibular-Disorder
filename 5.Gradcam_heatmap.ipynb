{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1536cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn import metrics\n",
    "import cv2\n",
    "from collections import Counter as cnt\n",
    "from torchvision import transforms\n",
    "from keras import Sequential\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix\n",
    "from torch import optim\n",
    "\n",
    "from Mymodule.ModelHandler import *\n",
    "from Mymodule.Utils import *\n",
    "from Mymodule.GradCam import *\n",
    "from Mymodule.BatchHandler import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adcbb65",
   "metadata": {},
   "source": [
    "## Visualize Grad-Cam Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model_name = 'vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explort_imgs(images, parent_dir,candidates):\n",
    "    for i,image in enumerate(images):\n",
    "        file_path = os.path.join(parent_dir, f'{candidates[i]}')\n",
    "        print(file_path)\n",
    "        cv2.imwrite(file_path, image)\n",
    "    print('exported..done')\n",
    "    \n",
    "def calculate_zero_ratios(img):\n",
    "    w, h = img.shape\n",
    "    zeros = 0\n",
    "    for i in range(w):\n",
    "        for j in range(w):\n",
    "            if img[i, j] <= 0:\n",
    "                zeros += 1\n",
    "    return zeros / (w*h)\n",
    "\n",
    "class LayerActivation():\n",
    "    features = None    \n",
    "    def __init__(self, model, layer_num):\n",
    "        self.hook = model.base.features[layer_num].register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = output.cpu().data.numpy()\n",
    "    def remove(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "        \n",
    "activation = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ef85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './Data/Images/'\n",
    "candidates = os.listdir(root)[1:]\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2748d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for i, candidate in enumerate(candidates):\n",
    "    if candidate[-3:] != 'png': continue\n",
    "        \n",
    "    image_path = os.path.join(root,candidate)\n",
    "    image = cv2.imread(image_path)\n",
    "    print(candidate)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "    image = cv2.resize(image,(140,140))\n",
    "    images.append(image)\n",
    "images = np.array(images).copy()\n",
    "test_y = np.zeros([16,1])\n",
    "print(images.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43608382",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = GetLoader([], images, test_y, batch=len(test_y), test=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d05a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_strategy in ['finetuning']:\n",
    "    for i,(data, label) in enumerate(test_loader):\n",
    "        data = data\n",
    "        label = label\n",
    "        model_save_path = f'./Model/vgg16_{train_strategy}.pt'\n",
    "        \n",
    "        model = get_model(model_name, device, pretrained=True)    \n",
    "        model.load_state_dict(torch.load(model_save_path))\n",
    "        model.eval()\n",
    "        \n",
    "        last_layer = model.base.features[-2]\n",
    "        cam = GradCAM(model=model, target_layer=last_layer, device=device)\n",
    "        grayscale_cam = cam(input_tensor=data, target_category=0)\n",
    "        \n",
    "    visuals = get_visuals(images/255, grayscale_cam)\n",
    "    explort_imgs(visuals, f'./Figures/Gradcam/', candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1b6201",
   "metadata": {},
   "source": [
    "## Visualize model output Feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85782c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerActivation():\n",
    "    features = None    \n",
    "    def __init__(self, model, layer_num):\n",
    "        self.hook = model.base.features[layer_num].register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = output.cpu().data.numpy()\n",
    "    def remove(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "        \n",
    "activation = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def calculate_zero_ratios(img):\n",
    "    w, h = img.shape\n",
    "    zeros = 0\n",
    "    for i in range(w):\n",
    "        for j in range(w):\n",
    "            if img[i, j] <= 0:\n",
    "                zeros += 1\n",
    "    return zeros / (w*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55350b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './Data/Images/'\n",
    "candidates = os.listdir(root)[1:]\n",
    "candidates\n",
    "\n",
    "x_start = 200\n",
    "y_start = 200\n",
    "x_end = x_start + 300\n",
    "y_end = y_start + 400\n",
    "\n",
    "MRIs = []\n",
    "images = []\n",
    "for i, candidate in enumerate(candidates):\n",
    "    if candidate[-3:] != 'png': continue\n",
    "    image_path = os.path.join(root,candidate)\n",
    "        \n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image,(140,140))\n",
    "    images.append(image)\n",
    "images = np.array(images)\n",
    "test_y = np.zeros([16,1])\n",
    "print(images.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b4bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    test_loader = GetLoader([], images[i][None], test_y[i][None], batch=len(test_y), test=True)  \n",
    "    for train_strategy in ['finetuning']:\n",
    "        device = torch.device('cuda:1')\n",
    "        model_name = 'vgg16'\n",
    "        model = get_model(model_name, device, pretrained=False)\n",
    "        model_path = f'./Model/vgg16_{train_strategy}.pt'\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        conv_out = LayerActivation(model, 42)\n",
    "\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            labels = label.float()\n",
    "            logits = model(data)\n",
    "\n",
    "        conv_out.remove()\n",
    "\n",
    "        maps = conv_out.features\n",
    "\n",
    "        fig = plt.figure(figsize=(13,4))\n",
    "        fig.subplots_adjust(left=0, right=1, bottom=0, top=0.8, hspace=0.1, wspace=0.1)\n",
    "\n",
    "        mean_zero_ratio = 0.0\n",
    "\n",
    "        for j in range(512):\n",
    "            if j < 100:\n",
    "                ax = fig.add_subplot(5, 20, j+1, xticks=[], yticks=[])\n",
    "                ax.imshow(maps[0][j])\n",
    "            mean_zero_ratio += calculate_zero_ratios(maps[0][j])\n",
    "\n",
    "        mean_zero_ratio /= 512\n",
    "        plt.savefig(f'./Figures/{candidates[i][:-4]}_heatmap_{mean_zero_ratio}.png')\n",
    "        plt.show()\n",
    "        print('%.4f' % mean_zero_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9b53f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JSG_image",
   "language": "python",
   "name": "jsg_image"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
